# esgaliant

**noun**. _Bridge over veiled river_ (Sindarin)

_esgal_ (“veil, screen, cover”) + _iant_ (“bridge”)

![Esgaliant Logo](assets/Esgaliant.png)

# Bridging Bio-AI Models

We are in the era of data-intensive biology. An era filled with the promise of effective therapeutics, of disappearing diseases, and an overall “good time” for humanity.

There are some caveats. A small thorn in our collective foot.

Biological datasets are immense — so immense that some might find it easier to send physical drives rather than rely on a spotty internet connection to share the fruits of their labor. At the rate we are accumulating data, even large-scale initiatives and atlases will struggle to ingest more, let alone provide bigger and better resources.

Resources that will, undeniably, be used to train large Bio-AI models. More cells. More conditions. More power. More storage.

We asked ourselves: instead of integrating datasets, could we integrate models?

Could we create a bridge to cross the veil between latent spaces, if you will?

## Synthetic Anchors

To achieve this goal, we will first develop effective synthetic datasets for single-cell and spatial multi-omics. Synthetic data points will serve as anchors, showing us how to bend, transform, flip, rotate, and fit latent spaces across modalities and models.

Our anchors will be generated through a synthetic/simulated data hybrid model to ensure strong resemblance to real data, but with transparent biological signals.

## Building Bridges

With our synthetic anchors, we aim to provide an effective model and toolkit to integrate architectures across diverse data modalities. As proof of concept, we will focus on single-cell datasets (including multi-modal data) and a range of dimensionality reduction methods (PCA, UMAP, AE, VAE, Transformers, etc.).

## Scale, Scale, Scale

If (as an alternative to the certainty of “once”) our model integrates latent spaces, we will increase the scale of integration through distributed and lightweight strategies. Our long-term objective is to integrate foundational models, or to create obscenely large foundational models, by directly linking those produced by researchers across the globe rather than by a single team with a very big computer.

# Lifecycle

Right now, esgaliant is nothing but an idea: the lecherous gaze of a researcher reading exciting new papers and too much sci-fi for their own good.

"Version 0.1.0"