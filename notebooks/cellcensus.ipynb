{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import tiledbsoma as soma\n",
    "import zarr\n",
    "import os\n",
    "from typing import Literal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4314f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" release is currently 2025-01-30. Specify 'census_version=\"2025-01-30\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1...\n",
      "  Chunk 1 complete: 134217728 values processed\n",
      "Processing chunk 2...\n",
      "  Chunk 2 complete: 134217728 values processed\n",
      "Processing chunk 3...\n",
      "  Chunk 3 complete: 134217728 values processed\n",
      "Processing chunk 4...\n",
      "  Chunk 4 complete: 134217728 values processed\n",
      "Processing chunk 5...\n",
      "  Chunk 5 complete: 134217728 values processed\n",
      "Processing chunk 6...\n",
      "  Chunk 6 complete: 134217728 values processed\n",
      "Processing chunk 7...\n",
      "  Chunk 7 complete: 134217728 values processed\n",
      "Processing chunk 8...\n",
      "  Chunk 8 complete: 134217728 values processed\n",
      "Processing chunk 9...\n",
      "  Chunk 9 complete: 134217728 values processed\n",
      "Processing chunk 10...\n",
      "  Chunk 10 complete: 134217728 values processed\n",
      "Processing chunk 11...\n",
      "  Chunk 11 complete: 134217728 values processed\n",
      "Processing chunk 12...\n",
      "  Chunk 12 complete: 134217728 values processed\n",
      "Processing chunk 13...\n",
      "  Chunk 13 complete: 134217728 values processed\n",
      "Processing chunk 14...\n",
      "  Chunk 14 complete: 134217728 values processed\n",
      "Processing chunk 15...\n",
      "  Chunk 15 complete: 134217728 values processed\n",
      "Processing chunk 16...\n",
      "  Chunk 16 complete: 134217728 values processed\n",
      "Processing chunk 17...\n",
      "  Chunk 17 complete: 134217728 values processed\n",
      "Processing chunk 18...\n",
      "  Chunk 18 complete: 134217728 values processed\n",
      "Processing chunk 19...\n",
      "  Chunk 19 complete: 134217728 values processed\n",
      "Processing chunk 20...\n",
      "  Chunk 20 complete: 134217728 values processed\n",
      "Processing chunk 21...\n",
      "  Chunk 21 complete: 134217728 values processed\n",
      "Processing chunk 22...\n",
      "  Chunk 22 complete: 134217728 values processed\n",
      "Processing chunk 23...\n",
      "  Chunk 23 complete: 134217728 values processed\n",
      "Processing chunk 24...\n",
      "  Chunk 24 complete: 134217728 values processed\n",
      "Processing chunk 25...\n",
      "  Chunk 25 complete: 134217728 values processed\n",
      "Processing chunk 26...\n",
      "  Chunk 26 complete: 134217728 values processed\n",
      "Processing chunk 27...\n",
      "  Chunk 27 complete: 134217728 values processed\n",
      "Processing chunk 28...\n",
      "  Chunk 28 complete: 134217728 values processed\n",
      "Processing chunk 29...\n",
      "  Chunk 29 complete: 134217728 values processed\n",
      "Processing chunk 30...\n",
      "  Chunk 30 complete: 134217728 values processed\n",
      "Processing chunk 31...\n",
      "  Chunk 31 complete: 134217728 values processed\n",
      "Processing chunk 32...\n",
      "  Chunk 32 complete: 134217728 values processed\n",
      "Processing chunk 33...\n",
      "  Chunk 33 complete: 134217728 values processed\n",
      "Processing chunk 34...\n",
      "  Chunk 34 complete: 134217728 values processed\n",
      "Processing chunk 35...\n",
      "  Chunk 35 complete: 134217728 values processed\n",
      "Processing chunk 36...\n",
      "  Chunk 36 complete: 134217728 values processed\n",
      "Processing chunk 37...\n",
      "  Chunk 37 complete: 134217728 values processed\n",
      "Processing chunk 38...\n",
      "  Chunk 38 complete: 134217728 values processed\n",
      "Processing chunk 39...\n",
      "  Chunk 39 complete: 134217728 values processed\n",
      "Processing chunk 40...\n",
      "  Chunk 40 complete: 134217728 values processed\n",
      "Processing chunk 41...\n",
      "  Chunk 41 complete: 134217728 values processed\n",
      "Processing chunk 42...\n",
      "  Chunk 42 complete: 134217728 values processed\n",
      "Processing chunk 43...\n",
      "  Chunk 43 complete: 134217728 values processed\n",
      "Processing chunk 44...\n",
      "  Chunk 44 complete: 134217728 values processed\n",
      "Processing chunk 45...\n",
      "  Chunk 45 complete: 134217728 values processed\n",
      "Processing chunk 46...\n",
      "  Chunk 46 complete: 134217728 values processed\n",
      "Processing chunk 47...\n",
      "  Chunk 47 complete: 134217728 values processed\n",
      "Processing chunk 48...\n",
      "  Chunk 48 complete: 134217728 values processed\n",
      "Processing chunk 49...\n",
      "  Chunk 49 complete: 134217728 values processed\n",
      "Processing chunk 50...\n",
      "  Chunk 50 complete: 134217728 values processed\n",
      "Processing chunk 51...\n",
      "  Chunk 51 complete: 134217728 values processed\n",
      "Processing chunk 52...\n",
      "  Chunk 52 complete: 134217728 values processed\n",
      "Processing chunk 53...\n",
      "  Chunk 53 complete: 134217728 values processed\n",
      "Processing chunk 54...\n",
      "  Chunk 54 complete: 134217728 values processed\n",
      "Processing chunk 55...\n",
      "  Chunk 55 complete: 134217728 values processed\n",
      "Processing chunk 56...\n",
      "  Chunk 56 complete: 134217728 values processed\n",
      "Processing chunk 57...\n",
      "  Chunk 57 complete: 134217728 values processed\n",
      "Processing chunk 58...\n",
      "  Chunk 58 complete: 134217728 values processed\n",
      "Processing chunk 59...\n",
      "  Chunk 59 complete: 134217728 values processed\n",
      "Processing chunk 60...\n",
      "  Chunk 60 complete: 134217728 values processed\n",
      "Processing chunk 61...\n",
      "  Chunk 61 complete: 134217728 values processed\n",
      "Processing chunk 62...\n",
      "  Chunk 62 complete: 134217728 values processed\n",
      "Processing chunk 63...\n",
      "  Chunk 63 complete: 134217728 values processed\n",
      "Processing chunk 64...\n",
      "  Chunk 64 complete: 134217728 values processed\n",
      "Processing chunk 65...\n",
      "  Chunk 65 complete: 134217728 values processed\n",
      "Processing chunk 66...\n",
      "  Chunk 66 complete: 134217728 values processed\n",
      "Processing chunk 67...\n",
      "  Chunk 67 complete: 134217728 values processed\n",
      "Processing chunk 68...\n",
      "  Chunk 68 complete: 134217728 values processed\n",
      "Processing chunk 69...\n",
      "  Chunk 69 complete: 134217728 values processed\n",
      "Processing chunk 70...\n",
      "  Chunk 70 complete: 134217728 values processed\n",
      "Processing chunk 71...\n",
      "  Chunk 71 complete: 134217728 values processed\n",
      "Processing chunk 72...\n",
      "  Chunk 72 complete: 134217728 values processed\n",
      "Processing chunk 73...\n",
      "  Chunk 73 complete: 134217728 values processed\n",
      "Processing chunk 74...\n",
      "  Chunk 74 complete: 134217728 values processed\n",
      "Processing chunk 75...\n",
      "  Chunk 75 complete: 134217728 values processed\n",
      "Processing chunk 76...\n",
      "  Chunk 76 complete: 134217728 values processed\n",
      "Processing chunk 77...\n",
      "  Chunk 77 complete: 134217728 values processed\n",
      "Processing chunk 78...\n",
      "  Chunk 78 complete: 134217728 values processed\n",
      "Processing chunk 79...\n",
      "  Chunk 79 complete: 134217728 values processed\n",
      "Processing chunk 80...\n",
      "  Chunk 80 complete: 134217728 values processed\n",
      "Processing chunk 81...\n",
      "  Chunk 81 complete: 134217728 values processed\n",
      "Processing chunk 82...\n",
      "  Chunk 82 complete: 134217728 values processed\n",
      "Processing chunk 83...\n",
      "  Chunk 83 complete: 134217728 values processed\n",
      "Processing chunk 84...\n",
      "  Chunk 84 complete: 134217728 values processed\n",
      "Processing chunk 85...\n",
      "  Chunk 85 complete: 134217728 values processed\n",
      "Processing chunk 86...\n",
      "  Chunk 86 complete: 134217728 values processed\n",
      "Processing chunk 87...\n",
      "  Chunk 87 complete: 134217728 values processed\n",
      "Processing chunk 88...\n",
      "  Chunk 88 complete: 134217728 values processed\n",
      "Processing chunk 89...\n",
      "  Chunk 89 complete: 134217728 values processed\n",
      "Processing chunk 90...\n",
      "  Chunk 90 complete: 134217728 values processed\n",
      "Processing chunk 91...\n",
      "  Chunk 91 complete: 134217728 values processed\n",
      "Processing chunk 92...\n",
      "  Chunk 92 complete: 134217728 values processed\n",
      "Processing chunk 93...\n",
      "  Chunk 93 complete: 134217728 values processed\n",
      "Processing chunk 94...\n",
      "  Chunk 94 complete: 134217728 values processed\n",
      "Processing chunk 95...\n",
      "  Chunk 95 complete: 134217728 values processed\n",
      "Processing chunk 96...\n",
      "  Chunk 96 complete: 134217728 values processed\n",
      "Processing chunk 97...\n",
      "  Chunk 97 complete: 134217728 values processed\n",
      "Processing chunk 98...\n",
      "  Chunk 98 complete: 134217728 values processed\n",
      "Processing chunk 99...\n",
      "  Chunk 99 complete: 134217728 values processed\n",
      "Processing chunk 100...\n",
      "  Chunk 100 complete: 134217728 values processed\n",
      "Processing chunk 101...\n",
      "  Chunk 101 complete: 134217728 values processed\n",
      "Processing chunk 102...\n",
      "  Chunk 102 complete: 134217728 values processed\n",
      "Processing chunk 103...\n",
      "  Chunk 103 complete: 134217728 values processed\n",
      "Processing chunk 104...\n",
      "  Chunk 104 complete: 134217728 values processed\n",
      "Processing chunk 105...\n",
      "  Chunk 105 complete: 134217728 values processed\n",
      "Processing chunk 106...\n",
      "  Chunk 106 complete: 134217728 values processed\n",
      "Processing chunk 107...\n",
      "  Chunk 107 complete: 134217728 values processed\n",
      "Processing chunk 108...\n",
      "  Chunk 108 complete: 134217728 values processed\n",
      "Processing chunk 109...\n",
      "  Chunk 109 complete: 134217728 values processed\n",
      "Processing chunk 110...\n",
      "  Chunk 110 complete: 134217728 values processed\n",
      "Processing chunk 111...\n",
      "  Chunk 111 complete: 134217728 values processed\n",
      "Processing chunk 112...\n",
      "  Chunk 112 complete: 134217728 values processed\n",
      "Processing chunk 113...\n",
      "  Chunk 113 complete: 134217728 values processed\n",
      "Processing chunk 114...\n",
      "  Chunk 114 complete: 134217728 values processed\n",
      "Processing chunk 115...\n",
      "  Chunk 115 complete: 134217728 values processed\n",
      "Processing chunk 116...\n",
      "  Chunk 116 complete: 134217728 values processed\n",
      "Processing chunk 117...\n",
      "  Chunk 117 complete: 134217728 values processed\n",
      "Processing chunk 118...\n",
      "  Chunk 118 complete: 134217728 values processed\n",
      "Processing chunk 119...\n",
      "  Chunk 119 complete: 134217728 values processed\n",
      "Processing chunk 120...\n",
      "  Chunk 120 complete: 134217728 values processed\n",
      "Processing chunk 121...\n",
      "  Chunk 121 complete: 134217728 values processed\n",
      "Processing chunk 122...\n",
      "  Chunk 122 complete: 134217728 values processed\n",
      "Processing chunk 123...\n",
      "  Chunk 123 complete: 134217728 values processed\n",
      "Processing chunk 124...\n",
      "  Chunk 124 complete: 134217728 values processed\n",
      "Processing chunk 125...\n",
      "  Chunk 125 complete: 134217728 values processed\n",
      "Processing chunk 126...\n",
      "  Chunk 126 complete: 134217728 values processed\n",
      "Processing chunk 127...\n",
      "  Chunk 127 complete: 134217728 values processed\n",
      "Processing chunk 128...\n",
      "  Chunk 128 complete: 134217728 values processed\n",
      "Processing chunk 129...\n",
      "  Chunk 129 complete: 134217728 values processed\n",
      "Processing chunk 130...\n",
      "  Chunk 130 complete: 134217728 values processed\n",
      "Processing chunk 131...\n",
      "  Chunk 131 complete: 134217728 values processed\n",
      "Processing chunk 132...\n",
      "  Chunk 132 complete: 134217728 values processed\n",
      "Processing chunk 133...\n",
      "  Chunk 133 complete: 134217728 values processed\n",
      "Processing chunk 134...\n",
      "  Chunk 134 complete: 134217728 values processed\n",
      "Processing chunk 135...\n",
      "  Chunk 135 complete: 134217728 values processed\n",
      "Processing chunk 136...\n",
      "  Chunk 136 complete: 134217728 values processed\n",
      "Processing chunk 137...\n",
      "  Chunk 137 complete: 134217728 values processed\n",
      "Processing chunk 138...\n",
      "  Chunk 138 complete: 134217728 values processed\n",
      "Processing chunk 139...\n",
      "  Chunk 139 complete: 134217728 values processed\n",
      "Processing chunk 140...\n",
      "  Chunk 140 complete: 134217728 values processed\n",
      "Processing chunk 141...\n",
      "  Chunk 141 complete: 134217728 values processed\n",
      "Processing chunk 142...\n",
      "  Chunk 142 complete: 134217728 values processed\n",
      "Processing chunk 143...\n",
      "  Chunk 143 complete: 134217728 values processed\n",
      "Processing chunk 144...\n",
      "  Chunk 144 complete: 134217728 values processed\n",
      "Processing chunk 145...\n",
      "  Chunk 145 complete: 134217728 values processed\n",
      "Processing chunk 146...\n",
      "  Chunk 146 complete: 134217728 values processed\n",
      "Processing chunk 147...\n",
      "  Chunk 147 complete: 134217728 values processed\n",
      "Processing chunk 148...\n",
      "  Chunk 148 complete: 134217728 values processed\n",
      "Processing chunk 149...\n",
      "  Chunk 149 complete: 134217728 values processed\n",
      "Processing chunk 150...\n",
      "  Chunk 150 complete: 134217728 values processed\n",
      "Processing chunk 151...\n",
      "  Chunk 151 complete: 134217728 values processed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSOMAError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Stream through X data in batches\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrow_tbl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing chunk \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk_idx\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cedars/esgaliant/esgaliant/.venv/lib/python3.13/site-packages/tiledbsoma/_read_iters.py:109\u001b[39m, in \u001b[36mTableReadIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> pa.Table:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cedars/esgaliant/esgaliant/.venv/lib/python3.13/site-packages/tiledbsoma/_read_iters.py:551\u001b[39m, in \u001b[36mArrowTableRead.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> pa.Table:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmq\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mSOMAError\u001b[39m: [ManagedQuery] [unnamed] Query FAILED: [TileDB::Query] Error: Query cancelled.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m mouse = census[\u001b[33m\"\u001b[39m\u001b[33mcensus_data\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmus_musculus\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Define your query filters here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mouse.axis_query(\n\u001b[32m      7\u001b[39m     measurement_name=\u001b[33m\"\u001b[39m\u001b[33mRNA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     obs_query=soma.AxisQuery(value_filter=\u001b[33m\"\u001b[39m\u001b[33mis_primary_data==True\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Add any other filters you need\u001b[39;00m\n\u001b[32m     10\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Get variable information\u001b[39;00m\n\u001b[32m     12\u001b[39m     var_df = query.var().concat().to_pandas()\n\u001b[32m     13\u001b[39m     n_vars = \u001b[38;5;28mlen\u001b[39m(var_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cedars/esgaliant/esgaliant/.venv/lib/python3.13/site-packages/tiledbsoma/_query.py:671\u001b[39m, in \u001b[36mExperimentAxisQuery.__exit__\u001b[39m\u001b[34m(self, *_)\u001b[39m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m    669\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[32m    672\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# Internals\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    from scipy.stats import wasserstein_distance\n",
    "except ImportError:\n",
    "    wasserstein_distance = None\n",
    "\n",
    "\n",
    "def compute_chunk_size(\n",
    "    n_cells: int = 10000,\n",
    "    n_genes: int = 2000,\n",
    "    max_chunk_size: int = 10000,\n",
    "    min_chunk_size: int = 1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute chunk sizes for zarr arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_cells : int\n",
    "        Number of cells (default: 10000)\n",
    "    n_genes : int\n",
    "        Number of genes (default: 2000)\n",
    "    max_chunk_size : int\n",
    "        Maximum chunk size (default: 10000)\n",
    "    min_chunk_size : int\n",
    "        Minimum chunk size (default: 1000)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple[int, int]\n",
    "        (gene_chunk_size, cell_chunk_size)\n",
    "    \"\"\"\n",
    "    if n_genes < min_chunk_size:\n",
    "        raise ValueError(\n",
    "            \"Number of genes should not be smaller than min chunk size.\"\n",
    "        )\n",
    "    if n_cells < min_chunk_size:\n",
    "        raise ValueError(\n",
    "            \"Number of cells should not be smaller than min chunk size.\"\n",
    "        )\n",
    "    gene_chunk_size = min(max_chunk_size, n_genes)\n",
    "    cell_chunk_size = min(max_chunk_size, n_cells)\n",
    "    return gene_chunk_size, cell_chunk_size\n",
    "\n",
    "\n",
    "def base_cell(\n",
    "    atlas: str = \"cellxgene\",\n",
    "    organism: str = \"mus_musculus\",\n",
    "    cell_types: None | list[str] = None,\n",
    "):\n",
    "    if atlas == \"cellxgene\":\n",
    "        gene_set = get_gene_set(atlas, organism)\n",
    "        base_cell = base_cellxgene(gene_set, organism, cell_types)\n",
    "        return gene_set, base_cell\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown atlas: {atlas}\")\n",
    "\n",
    "\n",
    "def get_gene_set(\n",
    "    atlas: str = \"cellxgene\",\n",
    "    organism: str = \"mus_musculus\",\n",
    "):\n",
    "    if atlas == \"cellxgene\":\n",
    "        with cellxgene_census.open_soma() as census:\n",
    "            genes = set(census[\"census_data\"][organism].ms[\"RNA\"].var.index)\n",
    "        return genes\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown atlas: {atlas}\")\n",
    "\n",
    "\n",
    "def base_cellxgene(\n",
    "    gene_set: list[str],\n",
    "    organism: str = \"mus_musculus\",\n",
    "    cell_types: list[str] | None = None,\n",
    ") -> npt.NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute mean expression for a gene set, optionally filtered by cell types.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    gene_set : list[str]\n",
    "        Compulsory. List of gene names to compute mean expression for.\n",
    "    organism : str\n",
    "        Organism name (default: \"mus_musculus\")\n",
    "    cell_types : list[str] | None\n",
    "        Optional. List of cell type values to filter on. If None, uses all cell types.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    npt.NDArray[np.float64]\n",
    "        Mean expression values for the gene set across selected cells.\n",
    "    \"\"\"\n",
    "    # connect to cellxgene server\n",
    "    with cellxgene_census.open_soma() as census:\n",
    "        org = census[\"census_data\"][organism]\n",
    "\n",
    "        # Build obs_query with primary data filter\n",
    "        obs_filter = \"is_primary_data==True\"\n",
    "\n",
    "        # Add cell type filter if provided\n",
    "        if cell_types is not None:\n",
    "            cell_type_filter = \" && \".join(\n",
    "                [f'cell_type==\"{ct}\"' for ct in cell_types]\n",
    "            )\n",
    "            obs_filter = f\"({obs_filter}) && ({cell_type_filter})\"\n",
    "\n",
    "        # Always filter primary tissue to remove duplicate cells\n",
    "        with org.axis_query(\n",
    "            measurement_name=\"RNA\",\n",
    "            obs_query=soma.AxisQuery(value_filter=obs_filter),\n",
    "            var_query=soma.AxisQuery(\n",
    "                value_filter=\" || \".join(\n",
    "                    [f'feature_name==\"{gene}\"' for gene in gene_set]\n",
    "                )\n",
    "            ),\n",
    "        ) as query:\n",
    "            # Get variable information\n",
    "            var_df = query.var().concat().to_pandas()\n",
    "            n_vars = len(var_df)\n",
    "            n_obs = query.n_obs\n",
    "\n",
    "            print(f\"Filtering for {n_obs} cells and {n_vars} genes\")\n",
    "\n",
    "            # Initialize accumulators for per-gene means\n",
    "            gene_sum = np.zeros((n_vars,), dtype=np.float64)\n",
    "            gene_count = np.zeros((n_vars,), dtype=np.int64)\n",
    "\n",
    "            # Get indexer to map soma_joinid to positional indices\n",
    "            indexer = query.indexer\n",
    "\n",
    "            # Stream through X data in batches\n",
    "            for chunk_idx, arrow_tbl in enumerate(query.X(\"raw\").tables()):\n",
    "                print(f\"Processing chunk {chunk_idx + 1}...\")\n",
    "\n",
    "                # Get positional indices for genes (var dimension)\n",
    "                var_pos = indexer.by_var(arrow_tbl[\"soma_dim_1\"])\n",
    "                # Get the data values\n",
    "                data = arrow_tbl[\"soma_data\"].to_numpy()\n",
    "\n",
    "                # Accumulate sums and counts per gene\n",
    "                np.add.at(gene_sum, var_pos, data)\n",
    "                np.add.at(gene_count, var_pos, 1)\n",
    "\n",
    "                print(\n",
    "                    f\"  Chunk {chunk_idx + 1} complete: {len(data)} values processed\"\n",
    "                )\n",
    "\n",
    "            # Compute final means\n",
    "            gene_mean = np.divide(\n",
    "                gene_sum,\n",
    "                n_obs,\n",
    "                where=(gene_count > 0),\n",
    "                out=np.zeros_like(gene_sum),\n",
    "            )\n",
    "    return gene_mean\n",
    "\n",
    "\n",
    "def cell_type_base(\n",
    "    zarr_store,\n",
    "    atlas: str = \"cellxgene\",\n",
    "    organism: str = \"mus_musculus\",\n",
    "    keep_all: bool = False,  # might remove this option\n",
    "    max_chunk_size: int = 5000,\n",
    "    min_chunk_size: int = 1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute mean expression per cell type and store in zarr store.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    zarr_store : str | zarr.Group\n",
    "        Path to zarr store or zarr Group object\n",
    "    atlas : str\n",
    "        Atlas name (default: \"cellxgene\")\n",
    "    organism : str\n",
    "        Organism name (default: \"mus_musculus\")\n",
    "    keep_all : bool\n",
    "        If True, keep all cell types. If False, use unique cell types only.\n",
    "    max_chunk_size : int\n",
    "        Maximum chunk size for zarr arrays (default: 5000)\n",
    "    min_chunk_size : int\n",
    "        Minimum chunk size for zarr arrays (default: 1000)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Results are stored in the zarr store.\n",
    "    \"\"\"\n",
    "    # Open zarr store if path is provided\n",
    "    if isinstance(zarr_store, str):\n",
    "        store = zarr.storage.LocalStore(zarr_store, read_only=False)\n",
    "        root = zarr.group(store)\n",
    "    else:\n",
    "        root = zarr_store\n",
    "\n",
    "    if atlas == \"cellxgene\":\n",
    "        # Get the atlas group\n",
    "        atlas_group_name = f\"{atlas}_base_cell\"\n",
    "        if atlas_group_name not in root:\n",
    "            raise ValueError(f\"Atlas group '{atlas_group_name}' not found in zarr store\")\n",
    "        \n",
    "        atlas_group = root[atlas_group_name]\n",
    "        \n",
    "        # Read gene names from zarr store\n",
    "        if \"var\" not in atlas_group or \"gene_names\" not in atlas_group[\"var\"]:\n",
    "            raise ValueError(\"Gene names not found in zarr store. Please initialize the store first.\")\n",
    "        \n",
    "        gene_set = list(atlas_group[\"var\"][\"gene_names\"][:])\n",
    "        gene_set_size = len(gene_set)\n",
    "        \n",
    "        print(f\"Found {gene_set_size} genes in zarr store\")\n",
    "        \n",
    "        # Get unique cell types from cellxgene\n",
    "        with cellxgene_census.open_soma() as census:\n",
    "            cell_meta_data = cellxgene_census.get_obs(\n",
    "                census, organism, column_names=[\"cell_type\"]\n",
    "            )\n",
    "            if keep_all:\n",
    "                cell_types = list(cell_meta_data[\"cell_type\"].unique())\n",
    "            else:\n",
    "                cell_types = sorted(list(set(cell_meta_data[\"cell_type\"])))\n",
    "        \n",
    "        n_cell_types = len(cell_types)\n",
    "        print(f\"Computing mean expression for {n_cell_types} cell types\")\n",
    "        \n",
    "        # Check if base_cell array exists and has correct shape\n",
    "        if \"base_cell\" not in atlas_group:\n",
    "            raise ValueError(\"base_cell array not found in zarr store. Please initialize the store first.\")\n",
    "        \n",
    "        base_cell_array = atlas_group[\"base_cell\"]\n",
    "        expected_shape = (n_cell_types + 1, gene_set_size)  # +1 for overall mean at row 0\n",
    "        \n",
    "        # Check array dimensions\n",
    "        if base_cell_array.shape[1] != gene_set_size:\n",
    "            raise ValueError(\n",
    "                f\"Gene dimension mismatch: store has {base_cell_array.shape[1]} genes, \"\n",
    "                f\"but gene_names has {gene_set_size} genes\"\n",
    "            )\n",
    "        \n",
    "        if base_cell_array.shape[0] < expected_shape[0]:\n",
    "            raise ValueError(\n",
    "                f\"Array too small: base_cell array has {base_cell_array.shape[0]} rows, \"\n",
    "                f\"but need {expected_shape[0]} rows (1 for overall mean + {n_cell_types} for cell types). \"\n",
    "                f\"Please reinitialize the store with the correct number of cell types.\"\n",
    "            )\n",
    "        \n",
    "        # Compute mean expression for each cell type\n",
    "        for idx, cell_type in enumerate(cell_types):\n",
    "            print(f\"Processing cell type {idx + 1}/{n_cell_types}: {cell_type}\")\n",
    "            cell_type_mean = base_cellxgene(gene_set, organism, [cell_type])\n",
    "            \n",
    "            # Store in zarr array (row idx + 1, since row 0 is overall mean)\n",
    "            row_idx = idx + 1\n",
    "            base_cell_array[row_idx, :] = cell_type_mean\n",
    "        \n",
    "        # Update cell_id array with cell type names\n",
    "        # Note: zarr arrays can't be resized, so we delete and recreate if size differs\n",
    "        if \"obs\" in atlas_group and \"cell_id\" in atlas_group[\"obs\"]:\n",
    "            cell_id_array = atlas_group[\"obs\"][\"cell_id\"]\n",
    "            if len(cell_id_array) != n_cell_types:\n",
    "                # Delete and recreate with correct size\n",
    "                del atlas_group[\"obs\"][\"cell_id\"]\n",
    "                gene_chunk_size, cell_chunk_size = compute_chunk_size(\n",
    "                    n_cell_types, gene_set_size, max_chunk_size, min_chunk_size\n",
    "                )\n",
    "                atlas_group[\"obs\"].create_array(\n",
    "                    \"cell_id\",\n",
    "                    data=cell_types,\n",
    "                    shape=None,\n",
    "                    dtype=None,\n",
    "                    chunks=(cell_chunk_size,),\n",
    "                )\n",
    "            else:\n",
    "                # Update in place\n",
    "                cell_id_array[:] = cell_types\n",
    "        else:\n",
    "            # Create cell_id array\n",
    "            if \"obs\" not in atlas_group:\n",
    "                atlas_group.create_group(\"obs\")\n",
    "            gene_chunk_size, cell_chunk_size = compute_chunk_size(\n",
    "                n_cell_types, gene_set_size, max_chunk_size, min_chunk_size\n",
    "            )\n",
    "            atlas_group[\"obs\"].create_array(\n",
    "                \"cell_id\",\n",
    "                data=cell_types,\n",
    "                shape=None,\n",
    "                dtype=None,\n",
    "                chunks=(cell_chunk_size,),\n",
    "            )\n",
    "        \n",
    "        # Update metadata\n",
    "        atlas_group.attrs[\"n_cells\"] = n_cell_types\n",
    "        root.attrs[\"n_cells\"] = n_cell_types\n",
    "        \n",
    "        print(f\"Successfully computed and stored mean expression for {n_cell_types} cell types\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown atlas: {atlas}\")\n",
    "\n",
    "\n",
    "def _compute_euclidean_distance(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Compute Euclidean distance between two vectors.\"\"\"\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "\n",
    "def _compute_cosine_distance(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine distance between two vectors.\"\"\"\n",
    "    dot_product = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    if norm_x == 0 or norm_y == 0:\n",
    "        return 1.0  # Maximum distance if one vector is zero\n",
    "    cosine_sim = dot_product / (norm_x * norm_y)\n",
    "    return 1 - cosine_sim  # Convert similarity to distance\n",
    "\n",
    "\n",
    "def _compute_manhattan_distance(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Compute Manhattan (L1) distance between two vectors.\"\"\"\n",
    "    return np.sum(np.abs(x - y))\n",
    "\n",
    "\n",
    "def _compute_wasserstein_distance(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Compute Wasserstein distance between two vectors.\"\"\"\n",
    "    if wasserstein_distance is None:\n",
    "        raise ImportError(\"scipy is required for Wasserstein distance computation\")\n",
    "    # For 1D distributions, we can use scipy's wasserstein_distance\n",
    "    # We need to normalize to create proper probability distributions\n",
    "    x_norm = x / (np.sum(x) + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "    y_norm = y / (np.sum(y) + 1e-10)\n",
    "    # Create positions for the distributions (gene indices)\n",
    "    positions = np.arange(len(x))\n",
    "    return wasserstein_distance(positions, positions, x_norm, y_norm)\n",
    "\n",
    "\n",
    "def cell_diff(\n",
    "    zarr_store,\n",
    "    atlas: str = \"cellxgene\",\n",
    "    distance_metrics: list[Literal[\"euclidean\", \"cosine\", \"manhattan\", \"wasserstein\"]] | None = None,\n",
    "    max_chunk_size: int = 5000,\n",
    "    min_chunk_size: int = 1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the difference and distances between the overall base_cell and each cell type's base_cell.\n",
    "    \n",
    "    This function:\n",
    "    1. Computes overall distances using multiple metrics (Euclidean, Cosine, Manhattan, Wasserstein)\n",
    "    2. Stores distances in a separate 'cell_distance' group\n",
    "    3. Computes normalized difference (cell_type_base - overall_base_cell) and replaces mean expression\n",
    "    4. Stores normalized differences in the base_cell array (replacing original mean expression)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    zarr_store : str | zarr.Group\n",
    "        Path to zarr store or zarr Group object\n",
    "    atlas : str\n",
    "        Atlas name (default: \"cellxgene\")\n",
    "    distance_metrics : list[str] | None\n",
    "        List of distance metrics to compute. Options: \"euclidean\", \"cosine\", \"manhattan\", \"wasserstein\".\n",
    "        If None, computes all available metrics.\n",
    "    max_chunk_size : int\n",
    "        Maximum chunk size for zarr arrays (default: 5000)\n",
    "    min_chunk_size : int\n",
    "        Minimum chunk size for zarr arrays (default: 1000)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Results are stored in the zarr store.\n",
    "    \"\"\"\n",
    "    # Open zarr store if path is provided\n",
    "    if isinstance(zarr_store, str):\n",
    "        store = zarr.storage.LocalStore(zarr_store, read_only=False)\n",
    "        root = zarr.group(store)\n",
    "    else:\n",
    "        root = zarr_store\n",
    "\n",
    "    if atlas == \"cellxgene\":\n",
    "        # Get the atlas group\n",
    "        atlas_group_name = f\"{atlas}_base_cell\"\n",
    "        if atlas_group_name not in root:\n",
    "            raise ValueError(f\"Atlas group '{atlas_group_name}' not found in zarr store\")\n",
    "        \n",
    "        atlas_group = root[atlas_group_name]\n",
    "        \n",
    "        # Check if base_cell array exists\n",
    "        if \"base_cell\" not in atlas_group:\n",
    "            raise ValueError(\"base_cell array not found in zarr store. Please run cell_type_base first.\")\n",
    "        \n",
    "        base_cell_array = atlas_group[\"base_cell\"]\n",
    "        n_rows, n_genes = base_cell_array.shape\n",
    "        \n",
    "        if n_rows < 2:\n",
    "            raise ValueError(\n",
    "                \"base_cell array must have at least 2 rows (1 for overall mean + at least 1 cell type). \"\n",
    "                \"Please run cell_type_base first.\"\n",
    "            )\n",
    "        \n",
    "        # Get the overall base_cell (row 0) - keep original for reference\n",
    "        overall_base_cell = base_cell_array[0, :].copy()\n",
    "        n_cell_types = n_rows - 1  # Subtract 1 for the overall mean row\n",
    "        \n",
    "        # Save original mean expressions before computing distances\n",
    "        # (in case this function is called multiple times)\n",
    "        original_cell_type_means = np.zeros((n_cell_types, n_genes), dtype=np.float64)\n",
    "        for idx in range(n_cell_types):\n",
    "            row_idx = idx + 1\n",
    "            original_cell_type_means[idx, :] = base_cell_array[row_idx, :].copy()\n",
    "        \n",
    "        # Get cell type names\n",
    "        if \"obs\" in atlas_group and \"cell_id\" in atlas_group[\"obs\"]:\n",
    "            cell_types = list(atlas_group[\"obs\"][\"cell_id\"][:])\n",
    "        else:\n",
    "            cell_types = [f\"cell_type_{i}\" for i in range(n_cell_types)]\n",
    "        \n",
    "        print(f\"Computing cell differences and distances for {n_cell_types} cell types\")\n",
    "        print(f\"Overall base_cell shape: {overall_base_cell.shape}\")\n",
    "        \n",
    "        # Set default distance metrics\n",
    "        if distance_metrics is None:\n",
    "            distance_metrics = [\"euclidean\", \"cosine\", \"manhattan\"]\n",
    "            if wasserstein_distance is not None:\n",
    "                distance_metrics.append(\"wasserstein\")\n",
    "        \n",
    "        # Compute chunk sizes\n",
    "        gene_chunk_size, cell_chunk_size = compute_chunk_size(\n",
    "            n_cell_types, n_genes, max_chunk_size, min_chunk_size\n",
    "        )\n",
    "        \n",
    "        # Create cell_distance group\n",
    "        if \"cell_distance\" in root:\n",
    "            distance_group = root[\"cell_distance\"]\n",
    "        else:\n",
    "            distance_group = root.create_group(\"cell_distance\")\n",
    "        \n",
    "        # Distance computation functions\n",
    "        distance_functions = {\n",
    "            \"euclidean\": _compute_euclidean_distance,\n",
    "            \"cosine\": _compute_cosine_distance,\n",
    "            \"manhattan\": _compute_manhattan_distance,\n",
    "        }\n",
    "        if wasserstein_distance is not None:\n",
    "            distance_functions[\"wasserstein\"] = _compute_wasserstein_distance\n",
    "        \n",
    "        # Compute distances for each metric using original mean expressions\n",
    "        distances = {}\n",
    "        for metric in distance_metrics:\n",
    "            if metric not in distance_functions:\n",
    "                print(f\"Warning: Metric '{metric}' not available, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Computing {metric} distances...\")\n",
    "            dist_func = distance_functions[metric]\n",
    "            metric_distances = np.zeros(n_cell_types, dtype=np.float64)\n",
    "            \n",
    "            for idx in range(n_cell_types):\n",
    "                cell_type_base = original_cell_type_means[idx, :]\n",
    "                metric_distances[idx] = dist_func(overall_base_cell, cell_type_base)\n",
    "            \n",
    "            # Store distances in zarr\n",
    "            if metric in distance_group:\n",
    "                dist_array = distance_group[metric]\n",
    "                if dist_array.shape != (n_cell_types,):\n",
    "                    del distance_group[metric]\n",
    "                    dist_array = distance_group.create_array(\n",
    "                        metric,\n",
    "                        data=metric_distances,\n",
    "                        shape=(n_cell_types,),\n",
    "                        dtype=np.float64,\n",
    "                        chunks=(cell_chunk_size,),\n",
    "                    )\n",
    "                else:\n",
    "                    dist_array[:] = metric_distances\n",
    "            else:\n",
    "                distance_group.create_array(\n",
    "                    metric,\n",
    "                    data=metric_distances,\n",
    "                    shape=(n_cell_types,),\n",
    "                    dtype=np.float64,\n",
    "                    chunks=(cell_chunk_size,),\n",
    "                )\n",
    "            \n",
    "            distances[metric] = metric_distances\n",
    "            print(f\"  {metric} distances computed: min={metric_distances.min():.4f}, max={metric_distances.max():.4f}, mean={metric_distances.mean():.4f}\")\n",
    "        \n",
    "        # Store cell type names in distance group\n",
    "        if \"cell_types\" in distance_group:\n",
    "            distance_group[\"cell_types\"][:] = cell_types\n",
    "        else:\n",
    "            distance_group.create_array(\n",
    "                \"cell_types\",\n",
    "                data=cell_types,\n",
    "                shape=None,\n",
    "                dtype=None,\n",
    "                chunks=(cell_chunk_size,),\n",
    "            )\n",
    "        \n",
    "        # Compute normalized differences using original mean expressions\n",
    "        # This shows if expression goes up (positive) or down (negative) compared to base\n",
    "        print(\"Computing normalized differences...\")\n",
    "        \n",
    "        # Normalize by the overall base_cell to get relative changes\n",
    "        # Avoid division by zero\n",
    "        overall_base_cell_normalized = overall_base_cell.copy()\n",
    "        overall_base_cell_normalized[overall_base_cell_normalized == 0] = 1.0  # Avoid division by zero\n",
    "        \n",
    "        normalized_diffs = np.zeros((n_cell_types, n_genes), dtype=np.float64)\n",
    "        \n",
    "        for idx in range(n_cell_types):\n",
    "            cell_type_base = original_cell_type_means[idx, :]\n",
    "            \n",
    "            # Compute normalized difference: (cell_type - base) / base\n",
    "            # This gives percentage change: positive = up, negative = down\n",
    "            normalized_diff = (cell_type_base - overall_base_cell) / overall_base_cell_normalized\n",
    "            normalized_diffs[idx, :] = normalized_diff\n",
    "        \n",
    "        # Replace mean expression in base_cell array with normalized differences\n",
    "        # Row 0 remains the overall base_cell, rows 1+ become normalized differences\n",
    "        for idx in range(n_cell_types):\n",
    "            row_idx = idx + 1\n",
    "            base_cell_array[row_idx, :] = normalized_diffs[idx, :]\n",
    "        \n",
    "        # Store metadata\n",
    "        atlas_group.attrs[\"cell_diff_computed\"] = True\n",
    "        atlas_group.attrs[\"normalized_differences\"] = True\n",
    "        distance_group.attrs[\"metrics\"] = distance_metrics\n",
    "        distance_group.attrs[\"n_cell_types\"] = n_cell_types\n",
    "        \n",
    "        print(f\"Successfully computed and stored:\")\n",
    "        print(f\"  - Distances for {len(distances)} metrics\")\n",
    "        print(f\"  - Normalized differences for {n_cell_types} cell types\")\n",
    "        print(f\"  - Normalized differences stored in base_cell array (rows 1+)\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown atlas: {atlas}\")\n",
    "\n",
    "\n",
    "def initialize_base_cell_store(\n",
    "    gene_set,\n",
    "    cell_set,\n",
    "    gene_mean,\n",
    "    atlas: str = \"cellxgene\",\n",
    "    zarr_path: str = \".\",\n",
    "    max_chunk_size: int = 5000,\n",
    "    min_chunk_size: int = 1000,\n",
    "):\n",
    "    if \".zarr\" not in zarr_path:\n",
    "        directory = zarr_path if zarr_path != \".\" else \".\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        store_name = f\"base_cell_{atlas}.zarr\"\n",
    "        zarr_path = os.path.join(directory, store_name)\n",
    "        print('No zarr store name provided - Generic name generated')\n",
    "        print(f'zarr store location: {zarr_path}')\n",
    "        \n",
    "    store = zarr.storage.LocalStore(zarr_path, read_only=False)\n",
    "    root = zarr.create_group(store)\n",
    "\n",
    "    cell_set_size = len(cell_set)\n",
    "    gene_set_size = len(gene_set)\n",
    "    cell_chunk_size, gene_chunk_size = compute_chunk_size(\n",
    "        cell_set_size, gene_set_size, max_chunk_size, min_chunk_size\n",
    "    )\n",
    "    atlas_group = root.create_group(f'{atlas}_base_cell')\n",
    "    atlas_group.create_array(\n",
    "        \"base_cell\",\n",
    "        shape=(cell_set_size + 1, gene_set_size),\n",
    "        dtype=np.float64,\n",
    "        chunks=(cell_chunk_size, gene_chunk_size),\n",
    "        fill_value=0.0,\n",
    "    )\n",
    "    atlas_group[\"base_cell\"][0,:] = gene_mean\n",
    "    # either cells types or all cells but better to use cell types\n",
    "    cell_id = atlas_group.create_group(\"obs\")\n",
    "    cell_id.create_array(\n",
    "        \"cell_id\",\n",
    "        data=cell_set,\n",
    "        shape=None,\n",
    "        dtype=None,\n",
    "        chunks=(cell_chunk_size,),\n",
    "    )\n",
    "    # Gene names stored seperately\n",
    "    gene_id = atlas_group.create_group(\"var\")\n",
    "    gene_id.create_array(\n",
    "        \"gene_names\",\n",
    "        data=gene_set,\n",
    "        shape=None,\n",
    "        dtype=None,\n",
    "        chunks=(gene_chunk_size,),\n",
    "    )\n",
    "    atlas_group.attrs[\"n_cells\"] = cell_set_size\n",
    "    atlas_group.attrs[\"n_genes\"] = gene_set_size\n",
    "    root.attrs[\"n_cells\"] = cell_set_size\n",
    "    root.attrs[\"n_genes\"] = gene_set_size\n",
    "\n",
    "    return root, zarr_path\n",
    "\n",
    "\n",
    "def plot_heatmap(\n",
    "    zarr_store,\n",
    "    atlas: str = \"cellxgene\",\n",
    "    output_path: str | None = None,\n",
    "    max_genes: int | None = None,\n",
    "    max_cell_types: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of normalized differences from the zarr store.\n",
    "    \n",
    "    The heatmap shows normalized differences (up/down regulation) for each cell type\n",
    "    compared to the base cell. Positive values (red) indicate up-regulation,\n",
    "    negative values (blue) indicate down-regulation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    zarr_store : str | zarr.Group\n",
    "        Path to zarr store or zarr Group object\n",
    "    atlas : str\n",
    "        Atlas name (default: \"cellxgene\")\n",
    "    output_path : str | None\n",
    "        Path to save the plot. If None, displays the plot.\n",
    "    max_genes : int | None\n",
    "        Maximum number of genes to display. If None, displays all.\n",
    "    max_cell_types : int | None\n",
    "        Maximum number of cell types to display. If None, displays all.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays or saves the heatmap plot.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "    except ImportError:\n",
    "        raise ImportError(\"matplotlib and seaborn are required for plotting. Install with: pip install matplotlib seaborn\")\n",
    "    \n",
    "    # Open zarr store if path is provided\n",
    "    if isinstance(zarr_store, str):\n",
    "        store = zarr.storage.LocalStore(zarr_store, read_only=False)\n",
    "        root = zarr.group(store)\n",
    "    else:\n",
    "        root = zarr_store\n",
    "\n",
    "    if atlas == \"cellxgene\":\n",
    "        # Get the atlas group\n",
    "        atlas_group_name = f\"{atlas}_base_cell\"\n",
    "        if atlas_group_name not in root:\n",
    "            raise ValueError(f\"Atlas group '{atlas_group_name}' not found in zarr store\")\n",
    "        \n",
    "        atlas_group = root[atlas_group_name]\n",
    "        \n",
    "        # Check if base_cell array exists\n",
    "        if \"base_cell\" not in atlas_group:\n",
    "            raise ValueError(\"base_cell array not found in zarr store.\")\n",
    "        \n",
    "        base_cell_array = atlas_group[\"base_cell\"]\n",
    "        n_rows, n_genes = base_cell_array.shape\n",
    "        \n",
    "        if n_rows < 2:\n",
    "            raise ValueError(\"base_cell array must have at least 2 rows.\")\n",
    "        \n",
    "        # Get normalized differences (rows 1+)\n",
    "        n_cell_types = n_rows - 1\n",
    "        normalized_diffs = base_cell_array[1:, :]  # Skip row 0 (overall base)\n",
    "        \n",
    "        # Get gene names\n",
    "        if \"var\" in atlas_group and \"gene_names\" in atlas_group[\"var\"]:\n",
    "            gene_names = list(atlas_group[\"var\"][\"gene_names\"][:])\n",
    "        else:\n",
    "            gene_names = [f\"gene_{i}\" for i in range(n_genes)]\n",
    "        \n",
    "        # Get cell type names\n",
    "        if \"obs\" in atlas_group and \"cell_id\" in atlas_group[\"obs\"]:\n",
    "            cell_types = list(atlas_group[\"obs\"][\"cell_id\"][:])\n",
    "        else:\n",
    "            cell_types = [f\"cell_type_{i}\" for i in range(n_cell_types)]\n",
    "        \n",
    "        # Limit display size if requested\n",
    "        if max_genes is not None and n_genes > max_genes:\n",
    "            # Select top varying genes\n",
    "            gene_variance = np.var(normalized_diffs, axis=0)\n",
    "            top_gene_indices = np.argsort(gene_variance)[-max_genes:]\n",
    "            normalized_diffs = normalized_diffs[:, top_gene_indices]\n",
    "            gene_names = [gene_names[i] for i in top_gene_indices]\n",
    "            print(f\"Displaying top {max_genes} most varying genes\")\n",
    "        \n",
    "        if max_cell_types is not None and n_cell_types > max_cell_types:\n",
    "            normalized_diffs = normalized_diffs[:max_cell_types, :]\n",
    "            cell_types = cell_types[:max_cell_types]\n",
    "            print(f\"Displaying first {max_cell_types} cell types\")\n",
    "        \n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(max(12, len(gene_names) * 0.1), max(8, len(cell_types) * 0.3)))\n",
    "        \n",
    "        # Use a diverging colormap: blue (negative/down) -> white (zero) -> red (positive/up)\n",
    "        vmax = np.max(np.abs(normalized_diffs))\n",
    "        vmin = -vmax\n",
    "        \n",
    "        sns.heatmap(\n",
    "            normalized_diffs,\n",
    "            xticklabels=gene_names,\n",
    "            yticklabels=cell_types,\n",
    "            cmap=\"RdBu_r\",  # Red-Blue reversed: red=up, blue=down\n",
    "            center=0,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cbar_kws={\"label\": \"Normalized Difference (Up/Down Regulation)\"},\n",
    "            linewidths=0.5,\n",
    "            linecolor=\"gray\",\n",
    "        )\n",
    "        \n",
    "        plt.title(\"Cell Type Expression Differences (Normalized)\\nRed = Up-regulation, Blue = Down-regulation\", \n",
    "                  fontsize=14, pad=20)\n",
    "        plt.xlabel(\"Genes\", fontsize=12)\n",
    "        plt.ylabel(\"Cell Types\", fontsize=12)\n",
    "        plt.xticks(rotation=90, ha=\"right\", fontsize=8)\n",
    "        plt.yticks(rotation=0, fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if output_path:\n",
    "            plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "            print(f\"Heatmap saved to {output_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown atlas: {atlas}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Cell type base expression and difference computation\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"command\",\n",
    "        choices=[\"init\", \"cell_type_base\", \"cell_diff\", \"plot\"],\n",
    "        help=\"Command to execute\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--zarr-store\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to zarr store\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--atlas\",\n",
    "        type=str,\n",
    "        default=\"cellxgene\",\n",
    "        help=\"Atlas name (default: cellxgene)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--organism\",\n",
    "        type=str,\n",
    "        default=\"mus_musculus\",\n",
    "        help=\"Organism name (default: mus_musculus)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--keep-all\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Keep all cell types (for cell_type_base)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-chunk-size\",\n",
    "        type=int,\n",
    "        default=5000,\n",
    "        help=\"Maximum chunk size for zarr arrays (default: 5000)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-chunk-size\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help=\"Minimum chunk size for zarr arrays (default: 1000)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--distance-metrics\",\n",
    "        nargs=\"+\",\n",
    "        choices=[\"euclidean\", \"cosine\", \"manhattan\", \"wasserstein\"],\n",
    "        help=\"Distance metrics to compute (for cell_diff). If not specified, computes all available.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        type=str,\n",
    "        help=\"Output path for plot (for plot command)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-genes\",\n",
    "        type=int,\n",
    "        help=\"Maximum number of genes to display in heatmap (for plot command)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-cell-types\",\n",
    "        type=int,\n",
    "        help=\"Maximum number of cell types to display in heatmap (for plot command)\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.command == \"init\":\n",
    "        print(\"Initializing base cell store...\")\n",
    "        gene_set, base_cell_mean = base_cell(\n",
    "            atlas=args.atlas,\n",
    "            organism=args.organism,\n",
    "        )\n",
    "        \n",
    "        # Get cell types for initialization\n",
    "        import cellxgene_census\n",
    "        with cellxgene_census.open_soma() as census:\n",
    "            cell_meta_data = cellxgene_census.get_obs(\n",
    "                census, args.organism, column_names=[\"cell_type\"]\n",
    "            )\n",
    "            cell_types = sorted(list(set(cell_meta_data[\"cell_type\"])))\n",
    "        \n",
    "        root, zarr_path = initialize_base_cell_store(\n",
    "            gene_set=list(gene_set),\n",
    "            cell_set=cell_types,\n",
    "            gene_mean=base_cell_mean,\n",
    "            atlas=args.atlas,\n",
    "            zarr_path=args.zarr_store,\n",
    "            max_chunk_size=args.max_chunk_size,\n",
    "            min_chunk_size=args.min_chunk_size,\n",
    "        )\n",
    "        print(f\"Base cell store initialized at: {zarr_path}\")\n",
    "    \n",
    "    elif args.command == \"cell_type_base\":\n",
    "        print(\"Computing cell type base expressions...\")\n",
    "        cell_type_base(\n",
    "            zarr_store=args.zarr_store,\n",
    "            atlas=args.atlas,\n",
    "            organism=args.organism,\n",
    "            keep_all=args.keep_all,\n",
    "            max_chunk_size=args.max_chunk_size,\n",
    "            min_chunk_size=args.min_chunk_size,\n",
    "        )\n",
    "        print(\"Cell type base expressions computed.\")\n",
    "    \n",
    "    elif args.command == \"cell_diff\":\n",
    "        print(\"Computing cell differences and distances...\")\n",
    "        cell_diff(\n",
    "            zarr_store=args.zarr_store,\n",
    "            atlas=args.atlas,\n",
    "            distance_metrics=args.distance_metrics,\n",
    "            max_chunk_size=args.max_chunk_size,\n",
    "            min_chunk_size=args.min_chunk_size,\n",
    "        )\n",
    "        print(\"Cell differences and distances computed.\")\n",
    "    \n",
    "    elif args.command == \"plot\":\n",
    "        print(\"Generating heatmap...\")\n",
    "        plot_heatmap(\n",
    "            zarr_store=args.zarr_store,\n",
    "            atlas=args.atlas,\n",
    "            output_path=args.output,\n",
    "            max_genes=args.max_genes,\n",
    "            max_cell_types=args.max_cell_types,\n",
    "        )\n",
    "        print(\"Heatmap generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b68109db",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test = \u001b[43mcensus\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcensus_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmus_musculus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mraw_mean_nnz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m test\n",
      "\u001b[31mTypeError\u001b[39m: 'DataFrame' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test = census[\"census_data\"][\"mus_musculus\"].obs['raw_mean_nnz']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb588182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" release is currently 2025-01-30. Specify 'census_version=\"2025-01-30\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    }
   ],
   "source": [
    "import cellxgene_census\n",
    "census = cellxgene_census.open_soma()\n",
    "cell_meta_data = cellxgene_census.get_obs(\n",
    "    census, \"mus_musculus\", column_names=[\"cell_type\"]\n",
    ")\n",
    "cell_meta_data = cell_meta_data['cell_type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824c7c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B cell',\n",
       " 'B cell zone reticular cell',\n",
       " 'Bergmann glial cell',\n",
       " 'CD103-positive dendritic cell',\n",
       " 'CD141-positive myeloid dendritic cell',\n",
       " 'CD1c-positive myeloid dendritic cell',\n",
       " 'CD4-positive, alpha-beta T cell',\n",
       " 'CD4-positive, alpha-beta memory T cell',\n",
       " 'CD4-positive, alpha-beta thymocyte',\n",
       " 'CD8-positive, alpha-beta T cell',\n",
       " 'CD8-positive, alpha-beta thymocyte',\n",
       " 'CD8_alpha-positive CD11b-negative dendritic cell',\n",
       " 'Cajal-Retzius cell',\n",
       " 'DN3 thymocyte',\n",
       " 'DN4 thymocyte',\n",
       " 'GABAergic amacrine cell',\n",
       " 'GABAergic neuron',\n",
       " 'IgM plasmablast',\n",
       " 'Kupffer cell',\n",
       " 'L2/3 intratelencephalic projecting glutamatergic neuron',\n",
       " 'L2/3 intratelencephalic projecting glutamatergic neuron of the primary motor cortex',\n",
       " 'L2/3-6 intratelencephalic projecting glutamatergic neuron',\n",
       " 'L4/5 intratelencephalic projecting glutamatergic neuron',\n",
       " 'L4/5 intratelencephalic projecting glutamatergic neuron of the primary motor cortex',\n",
       " 'L5 extratelencephalic projecting glutamatergic cortical neuron',\n",
       " 'L5 intratelencephalic projecting glutamatergic neuron',\n",
       " 'L5/6 near-projecting glutamatergic neuron',\n",
       " 'L5/6 near-projecting glutamatergic neuron of the primary motor cortex',\n",
       " 'L6 corticothalamic-projecting glutamatergic cortical neuron',\n",
       " 'L6 intratelencephalic projecting glutamatergic neuron',\n",
       " 'L6 intratelencephalic projecting glutamatergic neuron of the primary motor cortex',\n",
       " 'L6b glutamatergic cortical neuron',\n",
       " 'Langerhans cell',\n",
       " 'Leydig cell',\n",
       " 'Mueller cell',\n",
       " 'Purkinje cell',\n",
       " 'Schwann cell',\n",
       " 'Schwann cell precursor',\n",
       " 'Sertoli cell',\n",
       " 'T cell',\n",
       " 'T-helper 17 cell',\n",
       " 'VIP GABAergic cortical interneuron',\n",
       " 'activated CD4-negative, CD8-negative type I NK T cell',\n",
       " 'adipocyte',\n",
       " 'adipose macrophage',\n",
       " 'adventitial cell',\n",
       " 'alveolar macrophage',\n",
       " 'amacrine cell',\n",
       " 'aortic endothelial cell',\n",
       " 'aortic smooth muscle cell',\n",
       " 'astrocyte',\n",
       " 'astrocyte of the cerebellum',\n",
       " 'auditory epithelial cell',\n",
       " 'basal cell',\n",
       " 'basal cell of epidermis',\n",
       " 'basal cell of prostate epithelium',\n",
       " 'basal epithelial cell of tracheobronchial tree',\n",
       " 'basophil',\n",
       " 'bistratified retinal ganglion cell',\n",
       " 'bladder cell',\n",
       " 'bladder urothelial cell',\n",
       " 'blood cell',\n",
       " 'blood vessel endothelial cell',\n",
       " 'brain pericyte',\n",
       " 'brain vascular cell',\n",
       " 'bronchial smooth muscle cell',\n",
       " 'brown adipocyte',\n",
       " 'brown preadipocyte',\n",
       " 'brush cell',\n",
       " 'brush cell of epithelium proper of large intestine',\n",
       " 'capillary endothelial cell',\n",
       " 'cardiac muscle cell',\n",
       " 'cardiac neuron',\n",
       " 'cardiac valve cell',\n",
       " 'cell',\n",
       " 'cell of skeletal muscle',\n",
       " 'central nervous system macrophage',\n",
       " 'cerebellar Golgi cell',\n",
       " 'cerebellar granule cell',\n",
       " 'cerebellar granule cell precursor',\n",
       " 'cerebral cortex GABAergic interneuron',\n",
       " 'cerebral cortex endothelial cell',\n",
       " 'chondroblast',\n",
       " 'chondrocyte',\n",
       " 'choroid plexus epithelial cell',\n",
       " 'ciliated cell',\n",
       " 'ciliated cell of the bronchus',\n",
       " 'ciliated columnar cell of tracheobronchial tree',\n",
       " 'classical monocyte',\n",
       " 'club cell',\n",
       " 'cochlea auditory hair cell',\n",
       " 'common myeloid progenitor',\n",
       " 'conjunctiva goblet cell',\n",
       " 'connective tissue cell',\n",
       " 'conventional dendritic cell',\n",
       " 'corneal epithelial cell',\n",
       " 'cortical interneuron',\n",
       " 'corticothalamic-projecting glutamatergic cortical neuron',\n",
       " 'cranial motor neuron',\n",
       " 'dendritic cell',\n",
       " 'differentiation-committed oligodendrocyte precursor',\n",
       " 'double negative thymocyte',\n",
       " 'double-positive blast',\n",
       " 'double-positive, alpha-beta thymocyte',\n",
       " 'duct epithelial cell',\n",
       " 'early pro-B cell',\n",
       " 'ectodermal cell',\n",
       " 'effector CD4-positive, alpha-beta T cell',\n",
       " 'effector CD8-positive, alpha-beta T cell',\n",
       " 'efferent neuron',\n",
       " 'embryonic blood vessel endothelial progenitor cell',\n",
       " 'endo-epithelial cell',\n",
       " 'endocardial cell',\n",
       " 'endothelial cell',\n",
       " 'endothelial cell of artery',\n",
       " 'endothelial cell of coronary artery',\n",
       " 'endothelial cell of hepatic sinusoid',\n",
       " 'endothelial cell of lymphatic vessel',\n",
       " 'endothelial cell of vascular tree',\n",
       " 'endothelial stalk cell',\n",
       " 'enteric neuron',\n",
       " 'enterocyte of epithelium of large intestine',\n",
       " 'enterocyte of epithelium of small intestine',\n",
       " 'enteroendocrine cell',\n",
       " 'enteroendocrine cell of small intestine',\n",
       " 'enucleate erythrocyte',\n",
       " 'eosinophil',\n",
       " 'ependymal cell',\n",
       " 'epidermal cell',\n",
       " 'epithelial cell',\n",
       " 'epithelial cell of amnion',\n",
       " 'epithelial cell of large intestine',\n",
       " 'epithelial cell of pancreas',\n",
       " 'epithelial cell of parathyroid gland',\n",
       " 'epithelial cell of proximal tubule',\n",
       " 'epithelial cell of thymus',\n",
       " 'epithelial cell of thyroid gland',\n",
       " 'erythroblast',\n",
       " 'erythrocyte',\n",
       " 'erythroid lineage cell',\n",
       " 'erythroid progenitor cell',\n",
       " 'erythroid progenitor cell, mammalian',\n",
       " 'exocrine cell',\n",
       " 'extraembryonic cell',\n",
       " 'extrafusal muscle fiber',\n",
       " 'fallopian tube ciliated cell',\n",
       " 'fallopian tube secretory epithelial cell',\n",
       " 'female germ cell',\n",
       " 'fenestrated endothelial cell',\n",
       " 'fibroblast',\n",
       " 'fibroblast of cardiac tissue',\n",
       " 'fibroblast of connective tissue of prostate',\n",
       " 'fibroblast of dermis',\n",
       " 'fibroblast of lung',\n",
       " 'fibroblast of lymphatic vessel',\n",
       " 'fibrocyte',\n",
       " 'gamma-delta T cell',\n",
       " 'germ cell',\n",
       " 'germinal center B cell',\n",
       " 'gingival epithelial cell',\n",
       " 'glial cell',\n",
       " 'glioblast',\n",
       " 'glomerular endothelial cell',\n",
       " 'glutamatergic neuron',\n",
       " 'glycinergic amacrine cell',\n",
       " 'granulocyte',\n",
       " 'granulocyte monocyte progenitor cell',\n",
       " 'granulocytopoietic cell',\n",
       " 'granulosa cell',\n",
       " 'group 2 innate lymphoid cell',\n",
       " 'group 3 innate lymphoid cell',\n",
       " 'hair follicle melanocyte',\n",
       " 'hematopoietic cell',\n",
       " 'hematopoietic precursor cell',\n",
       " 'hematopoietic stem cell',\n",
       " 'hepatic stellate cell',\n",
       " 'hepatocyte',\n",
       " 'hippocampal neuron',\n",
       " 'hypendymal cell',\n",
       " 'hypertrophic chondrocyte',\n",
       " 'hypothalamus cell',\n",
       " 'immature B cell',\n",
       " 'immature NK T cell',\n",
       " 'immature T cell',\n",
       " 'immature astrocyte',\n",
       " 'inflammatory cell',\n",
       " 'inhibitory interneuron',\n",
       " 'innate lymphoid cell',\n",
       " 'intermediate mesodermal cell',\n",
       " 'intermediate monocyte',\n",
       " 'interneuron',\n",
       " 'interstitial cell of ovary',\n",
       " 'intestinal crypt stem cell',\n",
       " 'intestinal enteroendocrine cell',\n",
       " 'intestine goblet cell',\n",
       " 'intrahepatic cholangiocyte',\n",
       " 'iris pigment epithelial cell',\n",
       " 'keratinocyte',\n",
       " 'keratinocyte stem cell',\n",
       " 'kidney afferent arteriole endothelial cell',\n",
       " 'kidney capillary endothelial cell',\n",
       " 'kidney cell',\n",
       " 'kidney collecting duct epithelial cell',\n",
       " 'kidney collecting duct intercalated cell',\n",
       " 'kidney collecting duct principal cell',\n",
       " 'kidney connecting tubule epithelial cell',\n",
       " 'kidney cortex artery cell',\n",
       " 'kidney cortex tubule cell',\n",
       " 'kidney distal convoluted tubule epithelial cell',\n",
       " 'kidney efferent arteriole endothelial cell',\n",
       " 'kidney epithelial cell',\n",
       " 'kidney glomerular epithelial cell',\n",
       " 'kidney interstitial fibroblast',\n",
       " 'kidney loop of Henle ascending limb epithelial cell',\n",
       " 'kidney loop of Henle cortical thick ascending limb epithelial cell',\n",
       " 'kidney loop of Henle epithelial cell',\n",
       " 'kidney loop of Henle medullary thick ascending limb epithelial cell',\n",
       " 'kidney loop of Henle thick ascending limb epithelial cell',\n",
       " 'kidney loop of Henle thin ascending limb epithelial cell',\n",
       " 'kidney loop of Henle thin descending limb epithelial cell',\n",
       " 'kidney proximal convoluted tubule epithelial cell',\n",
       " 'kidney proximal straight tubule epithelial cell',\n",
       " 'kidney tubule cell',\n",
       " 'lamp5 GABAergic cortical interneuron',\n",
       " 'large intestine goblet cell',\n",
       " 'late pro-B cell',\n",
       " 'lateral mesodermal cell',\n",
       " 'lens epithelial cell',\n",
       " 'leptomeningeal cell',\n",
       " 'leukocyte',\n",
       " 'luminal cell of prostate epithelium',\n",
       " 'luminal epithelial cell of mammary gland',\n",
       " 'lung endothelial cell',\n",
       " 'lung macrophage',\n",
       " 'lung neuroendocrine cell',\n",
       " 'luteal cell',\n",
       " 'lymph node lymphatic vessel endothelial cell',\n",
       " 'lymphatic endothelial cell of medulla ceiling',\n",
       " 'lymphatic endothelial cell of subcapsular sinus ceiling',\n",
       " 'lymphatic endothelial cell of subcapsular sinus floor',\n",
       " 'lymphocyte',\n",
       " 'lymphoid lineage restricted progenitor cell',\n",
       " 'macroglial cell',\n",
       " 'macrophage',\n",
       " 'macrophage dendritic cell progenitor',\n",
       " 'macula densa epithelial cell',\n",
       " 'male germ cell',\n",
       " 'mammary gland epithelial cell',\n",
       " 'mast cell',\n",
       " 'mature CD4 single-positive thymocyte',\n",
       " 'mature CD8 single-positive thymocyte',\n",
       " 'mature NK T cell',\n",
       " 'mature alpha-beta T cell',\n",
       " 'medium spiny neuron',\n",
       " 'megakaryocyte',\n",
       " 'megakaryocyte-erythroid progenitor cell',\n",
       " 'meis2 expressing cortical GABAergic cell',\n",
       " 'melanocyte',\n",
       " 'memory B cell',\n",
       " 'meningeal macrophage',\n",
       " 'mesangial cell',\n",
       " 'mesenchymal cell',\n",
       " 'mesenchymal stem cell',\n",
       " 'mesenchymal stem cell of adipose tissue',\n",
       " 'mesodermal cell',\n",
       " 'mesothelial cell',\n",
       " 'mesothelial cell of epicardium',\n",
       " 'mesothelial cell of visceral pleura',\n",
       " 'metanephric mesenchyme stem cell',\n",
       " 'microglial cell',\n",
       " 'microvascular endothelial cell',\n",
       " 'monocyte',\n",
       " 'motor neuron',\n",
       " 'mucus secreting cell',\n",
       " 'mural cell',\n",
       " 'muscle cell',\n",
       " 'muscle fibroblast',\n",
       " 'muscle precursor cell',\n",
       " 'myelinating Schwann cell',\n",
       " 'myelocyte',\n",
       " 'myeloid cell',\n",
       " 'myeloid dendritic cell',\n",
       " 'myeloid leukocyte',\n",
       " 'myeloid suppressor cell',\n",
       " 'myoblast',\n",
       " 'myocyte of sinoatrial node',\n",
       " 'myofibroblast cell',\n",
       " 'myotube',\n",
       " 'naive B cell',\n",
       " 'naive T cell',\n",
       " 'naive thymus-derived CD4-positive, alpha-beta T cell',\n",
       " 'naive thymus-derived CD8-positive, alpha-beta T cell',\n",
       " 'natural killer cell',\n",
       " 'neural cell',\n",
       " 'neural progenitor cell',\n",
       " 'neural stem cell',\n",
       " 'neuroblast (sensu Vertebrata)',\n",
       " 'neuroendocrine cell',\n",
       " 'neuroepithelial stem cell',\n",
       " 'neuron',\n",
       " 'neutrophil',\n",
       " 'non-classical monocyte',\n",
       " 'non-myelinating Schwann cell',\n",
       " 'noradrenergic cell',\n",
       " 'notochordal cell',\n",
       " 'olfactory ensheathing cell',\n",
       " 'olfactory epithelial cell',\n",
       " 'olfactory receptor cell',\n",
       " 'oligodendrocyte',\n",
       " 'oligodendrocyte precursor cell',\n",
       " 'onychocyte',\n",
       " 'oocyte',\n",
       " 'oogonial cell',\n",
       " 'osteoblast',\n",
       " 'osteoclast',\n",
       " 'ovarian surface epithelial cell',\n",
       " 'pancreatic A cell',\n",
       " 'pancreatic D cell',\n",
       " 'pancreatic PP cell',\n",
       " 'pancreatic acinar cell',\n",
       " 'pancreatic ductal cell',\n",
       " 'pancreatic endocrine cell',\n",
       " 'pancreatic stellate cell',\n",
       " 'paneth cell of epithelium of small intestine',\n",
       " 'parasympathetic neuron',\n",
       " 'pericyte',\n",
       " 'peridermal cell',\n",
       " 'perineuronal satellite cell',\n",
       " 'peripheral nervous system neuron',\n",
       " 'perivascular macrophage',\n",
       " 'phagocyte',\n",
       " 'photoreceptor cell',\n",
       " 'pinealocyte',\n",
       " 'pituitary gland cell',\n",
       " 'plasma cell',\n",
       " 'plasmacytoid dendritic cell',\n",
       " 'plasmatocyte',\n",
       " 'podocyte',\n",
       " 'preadipocyte',\n",
       " 'precursor B cell',\n",
       " 'primitive erythroid progenitor',\n",
       " 'primitive red blood cell',\n",
       " 'primordial germ cell',\n",
       " 'proerythroblast',\n",
       " 'professional antigen presenting cell',\n",
       " 'progenitor cell',\n",
       " 'promonocyte',\n",
       " 'prostate gland microvascular endothelial cell',\n",
       " 'pulmonary alveolar type 1 cell',\n",
       " 'pulmonary alveolar type 2 cell',\n",
       " 'pulmonary interstitial fibroblast',\n",
       " 'pvalb GABAergic cortical interneuron',\n",
       " 'pyramidal neuron',\n",
       " 'regular atrial cardiac myocyte',\n",
       " 'regular ventricular cardiac myocyte',\n",
       " 'regulatory T cell',\n",
       " 'renal alpha-intercalated cell',\n",
       " 'renal beta-intercalated cell',\n",
       " 'respiratory basal cell',\n",
       " 'respiratory goblet cell',\n",
       " 'retina horizontal cell',\n",
       " 'retinal bipolar neuron',\n",
       " 'retinal cone cell',\n",
       " 'retinal ganglion cell',\n",
       " 'retinal pigment epithelial cell',\n",
       " 'retinal progenitor cell',\n",
       " 'retinal rod cell',\n",
       " 'rod bipolar cell',\n",
       " 'salivary gland cell',\n",
       " 'secretory cell',\n",
       " 'seminal vesicle glandular cell',\n",
       " 'sensory neuron of dorsal root ganglion',\n",
       " 'skeletal muscle fiber',\n",
       " 'skeletal muscle myoblast',\n",
       " 'skeletal muscle satellite cell',\n",
       " 'skeletal muscle satellite stem cell',\n",
       " 'skin fibroblast',\n",
       " 'small bistratified retinal ganglion cell',\n",
       " 'small intestine goblet cell',\n",
       " 'smooth muscle cell',\n",
       " 'smooth muscle cell of prostate',\n",
       " 'smooth muscle cell of the pulmonary artery',\n",
       " 'smooth muscle cell of trachea',\n",
       " 'sncg GABAergic cortical interneuron',\n",
       " 'spinal cord motor neuron',\n",
       " 'spiral ganglion neuron',\n",
       " 'splanchnic mesodermal cell',\n",
       " 'sst GABAergic cortical interneuron',\n",
       " 'sst chodl GABAergic cortical interneuron',\n",
       " 'starburst amacrine cell',\n",
       " 'stem cell',\n",
       " 'stem cell of epidermis',\n",
       " 'stromal cell',\n",
       " 'stromal cell of ovary',\n",
       " 'supporting cell',\n",
       " 'sympathetic neuron',\n",
       " 'tanycyte',\n",
       " 'tendon cell',\n",
       " 'thalamic excitatory neuron',\n",
       " 'theca cell',\n",
       " 'thymic macrophage',\n",
       " 'thymocyte',\n",
       " 'tissue-resident macrophage',\n",
       " 'transit amplifying cell of small intestine',\n",
       " 'trigeminal neuron',\n",
       " 'tuft cell of small intestine',\n",
       " 'type 1 cone bipolar cell (sensu Mus)',\n",
       " 'type 2 cone bipolar cell (sensu Mus)',\n",
       " 'type 3a cone bipolar cell',\n",
       " 'type 3b cone bipolar cell',\n",
       " 'type 4 cone bipolar cell (sensu Mus)',\n",
       " 'type 5 cone bipolar cell (sensu Mus)',\n",
       " 'type 5a cone bipolar cell',\n",
       " 'type 5b cone bipolar cell',\n",
       " 'type 6 cone bipolar cell (sensu Mus)',\n",
       " 'type 7 cone bipolar cell (sensu Mus)',\n",
       " 'type 8 cone bipolar cell (sensu Mus)',\n",
       " 'type 9 cone bipolar cell (sensu Mus)',\n",
       " 'type B pancreatic cell',\n",
       " 'type I cell of adrenal cortex',\n",
       " 'type I muscle cell',\n",
       " 'type II muscle cell',\n",
       " 'type IIa muscle cell',\n",
       " 'type IIb muscle cell',\n",
       " 'unipolar brush cell',\n",
       " 'unknown',\n",
       " 'ureteric bud cell',\n",
       " 'urethra urothelial cell',\n",
       " 'valve endothelial cell',\n",
       " 'valve interstitial cell',\n",
       " 'vasa recta descending limb cell',\n",
       " 'vascular associated smooth muscle cell',\n",
       " 'vascular leptomeningeal cell',\n",
       " 'vascular leptomeningeal cell (Mmus)',\n",
       " 'vein endothelial cell'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "set(cell_meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11077fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esgaliant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
